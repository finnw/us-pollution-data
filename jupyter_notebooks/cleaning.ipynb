{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e49f7d02",
   "metadata": {},
   "source": [
    "#### Import some required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57283c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6485dd",
   "metadata": {},
   "source": [
    "#### Read in the source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('../data/archive.zip', compression='zip')\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd3e632",
   "metadata": {},
   "source": [
    "#### Drop some redundant columns\n",
    "Also parse the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5371f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df0.drop(columns=['Unnamed: 0', 'State Code', 'County Code', 'Site Num', 'NO2 Units', 'O3 Units', 'SO2 Units', 'CO Units'])\n",
    "df1['Date Local'] = pd.to_datetime(df1['Date Local'])\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36debef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "\n",
    "class MeasureAggregator:\n",
    "    def __init__(self, measure_column, hour_column=None):\n",
    "        self.measure = measure_column\n",
    "        self.hour_column = hour_column\n",
    "        self.worst_value = None\n",
    "        self.worst_hour = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.worst_value = None\n",
    "        self.worst_hour = None\n",
    "\n",
    "    def consider(self, row):\n",
    "        value = row[self.measure]\n",
    "        if not np.isnan(value):\n",
    "            if self.worst_value is None or value > self.worst_value:\n",
    "                self.worst_value = value\n",
    "                self.worst_row = row\n",
    "                if self.hour_column is not None:\n",
    "                    hour = row[self.hour_column]\n",
    "                    self.worst_hour = hour\n",
    "\n",
    "    def update(self, dict):\n",
    "        if self.worst_value is not None:\n",
    "            dict[self.measure] = self.worst_value\n",
    "        else:\n",
    "            dict[self.measure] = np.nan\n",
    "        if self.hour_column is not None:\n",
    "            dict[self.hour_column] = self.worst_hour\n",
    "\n",
    "\n",
    "measures = [\n",
    "    MeasureAggregator('NO2 Mean'),\n",
    "    MeasureAggregator('NO2 1st Max Value', 'NO2 1st Max Hour'),\n",
    "    MeasureAggregator('NO2 AQI'),\n",
    "    MeasureAggregator('O3 Mean'),\n",
    "    MeasureAggregator('O3 1st Max Value', 'O3 1st Max Hour'),\n",
    "    MeasureAggregator('O3 AQI'),\n",
    "    MeasureAggregator('SO2 Mean'),\n",
    "    MeasureAggregator('SO2 1st Max Value', 'SO2 1st Max Hour'),\n",
    "    MeasureAggregator('SO2 AQI'),\n",
    "    MeasureAggregator('CO Mean'),\n",
    "    MeasureAggregator('CO 1st Max Value', 'CO 1st Max Hour'),\n",
    "    MeasureAggregator('CO AQI')\n",
    "]\n",
    "\n",
    "\n",
    "def aggregate_by_worst_reading(group):\n",
    "    global n  # Show progress as this process can be slow\n",
    "    n += 1\n",
    "    if n % 10000 == 0:\n",
    "        print(n)\n",
    "\n",
    "    for measure in measures:\n",
    "        measure.reset()\n",
    "    out = {}\n",
    "    # Copy the non-aggregated fields from the first row in the group\n",
    "    out['Address'] = group.iloc[0]['Address']\n",
    "    out['State'] = group.iloc[0]['State']\n",
    "    out['County'] = group.iloc[0]['County']\n",
    "    out['City'] = group.iloc[0]['City']\n",
    "    out['Date Local'] = group.iloc[0]['Date Local']\n",
    "    for _, row in group.iterrows():\n",
    "        for measure in measures:\n",
    "            measure.consider(row)\n",
    "    for measure in measures:\n",
    "        measure.update(out)\n",
    "    return pd.Series(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3592c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.groupby(['Address', 'Date Local']).apply(aggregate_by_worst_reading, include_groups=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "041cf6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('../data/cleaned_pollution_data.zip', index=False, compression='zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
